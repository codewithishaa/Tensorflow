{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ba62e5d",
   "metadata": {},
   "source": [
    "# TensorFlow by Isha Borgaonkar "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ce9160",
   "metadata": {},
   "source": [
    "##  Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9c6bba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\isha\\anaconda3\\lib\\site-packages (2.16.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\isha\\anaconda3\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: tensorflow-addons in c:\\users\\isha\\anaconda3\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: keras-tuner in c:\\users\\isha\\anaconda3\\lib\\site-packages (1.4.7)\n",
      "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow) (2.16.1)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (63.4.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.3.2)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: keras>=3.0.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.25.8)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (4.3.0)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.16.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (1.62.2)\n",
      "Requirement already satisfied: packaging in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (21.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (9.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: typeguard<3.0.0,>=2.7 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorflow-addons) (2.13.3)\n",
      "Requirement already satisfied: kt-legacy in c:\\users\\isha\\anaconda3\\lib\\site-packages (from keras-tuner) (1.0.5)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.8.0)\n",
      "Requirement already satisfied: optree in c:\\users\\isha\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: rich in c:\\users\\isha\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\isha\\anaconda3\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2025.4.26)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow) (3.10)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (2.17.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\isha\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "# Install TensorFlow for deep learning, matplotlib for plotting,\n",
    "# tensorflow-addons for extra layers/optimizers, and keras-tuner for hyperparameter search\n",
    "!pip install tensorflow matplotlib tensorflow-addons keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d18186f",
   "metadata": {},
   "source": [
    "## Imports & Environment Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec8b93f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Tuner version: 1.0.5\n",
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "# Core TensorFlow imports\n",
    "import tensorflow as tf                        # Core TensorFlow library\n",
    "from tensorflow import keras                   # High-level Keras API\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Plotting and array utilities\n",
    "import matplotlib.pyplot as plt                # For visualizing results\n",
    "import numpy as np                             # For numerical operations\n",
    "\n",
    "# Optional: Keras Tuner for hyperparameter search\n",
    "try:\n",
    "    import kerastuner as kt                    # install with: pip install keras-tuner\n",
    "    print(\"Keras Tuner version:\", kt.__version__)\n",
    "except ModuleNotFoundError:\n",
    "    print(\"⚠️ keras-tuner not found. Install with:\\n    pip install keras-tuner\")\n",
    "\n",
    "# Confirm TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26951322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Tuner version: 1.0.5\n",
      "TensorFlow version: 2.16.1\n"
     ]
    }
   ],
   "source": [
    "# Core TensorFlow imports\n",
    "import tensorflow as tf                        # Core TensorFlow library\n",
    "from tensorflow import keras                   # High-level Keras API\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Plotting and array utilities\n",
    "import matplotlib.pyplot as plt                # For visualizing results\n",
    "import numpy as np                             # For numerical operations\n",
    "\n",
    "# Optional: Keras Tuner for hyperparameter search\n",
    "try:\n",
    "    import kerastuner as kt                    # install with: pip install keras-tuner\n",
    "    print(\"Keras Tuner version:\", kt.__version__)\n",
    "except ModuleNotFoundError:\n",
    "    print(\"⚠️ keras-tuner not found. Install with:\\n    pip install keras-tuner\")\n",
    "\n",
    "# Confirm TensorFlow version\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf9af3",
   "metadata": {},
   "source": [
    "##  Loading & Exploring Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99359bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAUgUlEQVR4nO3cb6wWdP3/8fd1zoHDgYMoh8NAE04kTN1gmihESGqaWrqhFq47jUxvWGuuzf7YltpqUyvNlc5c1rRxw1VTs2maW7m1JJHMlIalIBlg/BMIOJxzOH++N37rvfqhcT4f4QD1eGzdwfM619XFOTy5QN+NoaGhoQCAiGg63E8AgCOHKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKPBfad26ddFoNOJb3/rWQfucTz/9dDQajXj66acP2ueEI40ocMS4//77o9FoxMqVKw/3UzlkHnzwwXjve98bY8aMic7OzvjUpz4VW7duPdxPC5IowAi555574uMf/3hMnDgx7rjjjrjmmmviwQcfjA9+8IPR09NzuJ8eREREy+F+AvC/oK+vL7785S/HokWL4qmnnopGoxEREQsWLIhLL700vv/978dnP/vZw/wswTsFjjJ9fX1x4403xhlnnBETJkyIcePGxdlnnx2//vWv33bz7W9/O6ZPnx5tbW3xgQ98IFatWrXfx7z88svx0Y9+NCZOnBhjxoyJuXPnxqOPPnrA59Pd3R0vv/zyAf8IaNWqVbFjx4648sorMwgREZdcckm0t7fHgw8+eMDHgpEgChxV/vGPf8R9990X55xzTtx2221x8803x5YtW+LCCy+MF154Yb+P/9GPfhTf+c534jOf+UzccMMNsWrVqjjvvPNi06ZN+TF/+tOfYv78+bF69er40pe+FLfffnuMGzcuFi9eHA8//PB/fD4rVqyIU045Je66667/+HG9vb0REdHW1rbfP2tra4s//OEPMTg4OIxXAA4tf3zEUeW4446LdevWxejRo/PHrrnmmjj55JPju9/9bvzgBz/4t49/9dVX45VXXokTTjghIiIuuuiimDdvXtx2221xxx13RETEddddF9OmTYvnnnsuWltbIyLi05/+dCxcuDC++MUvxmWXXfaOn/fMmTOj0WjEb3/72/jkJz+ZP/7nP/85tmzZEhER27dvj46Ojnf8WPBOeKfAUaW5uTmDMDg4GG+++Wb09/fH3Llz4/nnn9/v4xcvXpxBiIg466yzYt68efH4449HRMSbb74Zv/rVr2LJkiWxa9eu2Lp1a2zdujW2bdsWF154YbzyyiuxYcOGt30+55xzTgwNDcXNN9/8H5/3pEmTYsmSJfHAAw/E7bffHmvXro3f/OY3ceWVV8aoUaMiImLv3r2lLwccdKLAUeeBBx6IOXPmxJgxY6KjoyM6Ozvjsccei507d+73sTNnztzvx2bNmhXr1q2LiP/3TmJoaCi+8pWvRGdn57/976abboqIiM2bNx+U533vvffGhz/84bj++uvjPe95TyxatChmz54dl156aUREtLe3H5THgXfCHx9xVFm2bFksXbo0Fi9eHJ///Odj8uTJ0dzcHLfcckusWbOm+PP988/xr7/++rjwwgvf8mNOOumkd/Sc/2nChAnxs5/9LF5//fVYt25dTJ8+PaZPnx4LFiyIzs7OOPbYYw/K48A7IQocVX7605/GjBkz4qGHHvq3f4vnn7+r//+98sor+/3YX/7yl+jq6oqIiBkzZkRExKhRo+L8888/+E/4LUybNi2mTZsWERE7duyI3//+93HFFVeMyGPDgfjjI44qzc3NERExNDSUP/bss8/G8uXL3/LjH3nkkX/7O4EVK1bEs88+GxdffHFEREyePDnOOeecuPfee+ONN97Yb//PvwR+O8P9V1Lfzg033BD9/f3xuc99rmoPB5t3ChxxfvjDH8YTTzyx349fd911cckll8RDDz0Ul112WXzkIx+J1157Lb73ve/FqaeeGrt3795vc9JJJ8XChQvj2muvjd7e3rjzzjujo6MjvvCFL+TH3H333bFw4cKYPXt2XHPNNTFjxozYtGlTLF++PNavXx9//OMf3/a5rlixIs4999y46aabDviXzbfeemusWrUq5s2bFy0tLfHII4/EL3/5y/j6178eZ5555vBfIDiERIEjzj333POWP7506dJYunRp/P3vf4977703nnzyyTj11FNj2bJl8ZOf/OQtD9V94hOfiKamprjzzjtj8+bNcdZZZ8Vdd90VU6dOzY859dRTY+XKlfHVr3417r///ti2bVtMnjw5Tj/99LjxxhsP2v+v2bNnx8MPPxyPPvpoDAwMxJw5c+LHP/5xfOxjHztojwHvVGPoX9+HA/A/zd8pAJBEAYAkCgAkUQAgiQIASRQASMP+7xT+9aQAAEef4fwXCN4pAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQGo53E8ADqTRaBRvhoaGDsEz2d/48eOLNwsXLqx6rF/84hdVu1I1r3dzc3Pxpr+/v3hzpKt57Wodqq9x7xQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJAcxOOI19RU/nuXgYGB4s1JJ51UvLn66quLN3v37i3eRETs2bOneNPT01O8WbFiRfFmJI/b1Rydq/kaqnmckXwdao4QDod3CgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASA7iccSrOfxVcxDvvPPOK96cf/75xZv169cXbyIiWltbizdjx44t3lxwwQXFm/vuu694s2nTpuJNRMTQ0FDxpubroUZ7e3vVbnBwsHjT3d1d9VgH4p0CAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSg3gc8fr6+kbkcc4888ziTVdXV/Gm5sBfRERTU/nv4Z588snizemnn168+cY3vlG8WblyZfEmIuKll14q3qxevbp4c9ZZZxVvar6GIiKeeeaZ4s3y5curHutAvFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEByEI8R02g0qnZDQ0PFmwsuuKB4M3fu3OLNrl27ijfjxo0r3kREzJo1a0Q2zz33XPHm1VdfLd60t7cXbyIi3ve+9xVvLr/88uLNvn37ijc1r11ExNVXX1286e3trXqsA/FOAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASI2hYZ6grL1wyZHvSP+5rbmS+rvf/a5409XVVbypUft69/f3F2/6+vqqHqtUT09P8WZwcLDqsZ5//vniTc0V15rX+6KLLireRETMmDGjeHPCCScUb4bzveSdAgBJFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAUsvhfgIcfjUH545027dvL95MnTq1eLN3797iTWtra/EmIqKlpfzbtb29vXhTc9yura2teFN7EO/ss88u3ixYsKB409RU/nvmyZMnF28iIp544omq3aHgnQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJKDePxXGjt2bPGm5gBazaa7u7t4ExGxc+fO4s22bduKN11dXcWbmqOKjUajeBNR95rXfD0MDAwUb2qP/J144olVu0PBOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACQH8ag6TFZzlKzmwFhERHt7e/Hm+OOPL9709vaOyKa1tbV4ExHR19dXvKk5vnfssccWb2oO79UcqYuIGD16dPFm165dxZsJEyYUb1588cXiTUTd1/jcuXOrHutAvFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSK6nE0NBQ8aa5ubl4U3sl9corryzeTJkypXizZcuW4k1bW1vxZnBwsHgTETFu3LjizYknnli8qbnGWnP5dd++fcWbiIiWlvJftmp+njo6Ooo3d999d/EmIuK0004r3tS8DsPhnQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAFJjaJjX0BqNxqF+LhwmNYe1+vv7D8EzeWvz5s0r3jz22GPFm7179xZvRvIw4Pjx44s3PT09xZtt27YVb0aNGjUim4i6w4Dbt2+veqxSNa93RMQ3v/nN4s2yZcuKN8P55d47BQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoApPJLaIdY7eG9msNkTU3lTax5fvv27SveDA4OFm9qjeRxuxqPP/548WbPnj3Fm5qDeKNHjy7eDPMG5X62bNlSvKn5vhgzZkzxpuZrvNZIfT/VvHZz5swp3kRE7Ny5s2p3KHinAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAdEgP4tUclBoYGKh6rCP9qNuRbNGiRcWbK664onjz/ve/v3gTEdHd3V282bZtW/Gm5rhdS0v5t1Dt13jN61DzPdja2lq8qTmiV3sYsOZ1qFHz9bB79+6qx7r88suLNz//+c+rHutAvFMAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEBqDA3zKlWj0TjUz2XETZw4sXhz/PHHF29mzpw5Io8TUXdYa9asWcWb3t7e4k1TU93vQfbt21e8aWtrK95s3LixeDNq1KjiTc2htYiIjo6O4k1fX1/xZuzYscWbZ555pnjT3t5evImoO+A4ODhYvNm5c2fxpubrISJi06ZNxZtTTjmleDOcX+69UwAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFANIhvZI6f/784s3Xvva14k1ERGdnZ/Hm2GOPLd4MDAwUb5qbm4s3O3bsKN5ERPT39xdvaq5i1lzfrL20u3fv3uLN6tWrizdLliwp3qxcubJ4M378+OJNRMRxxx1XvOnq6qp6rFJr164t3tS+Drt27SredHd3F29qLu3WXn495phjijc137eupAJQRBQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFANKwD+K1tLQUf/Lly5cXb6ZOnVq8iag7VFezqTmsVaPmiF5E3fG4kTJhwoSq3aRJk4o3S5cuLd586EMfKt5ce+21xZuNGzcWbyIienp6ijevvfZa8abmuN3MmTOLNx0dHcWbiLpjjKNGjSre1Bzsq3mciIjBwcHizfTp04s3DuIBUEQUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQDSsA/iXXXVVcWf/NZbby3erFmzpngTEdHe3j4im9bW1uJNjdrDWjVH5/72t78Vb2qOunV2dhZvIiKamsp/7zJlypTizeLFi4s3Y8aMKd50dXUVbyLqvl7POOOMEdnU/BzVHLarfazRo0dXPVapRqNRtav5fp8/f37x5vXXXz/gx3inAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGA1DLcD9y8eXPxJ685tDZ+/PjiTUREb29v8abm+dUcJas5xnXMMccUbyIi3nzzzeLNX//61+JNzeuwd+/e4k1ERE9PT/Gmv7+/ePPwww8Xb1566aXiTe1BvIkTJxZvao7O7dixo3izb9++4k3Nz1FExODgYPGm5uBczePUHsSr+TVi1qxZVY91IN4pAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgDfsg3oYNG4o/+dDQUPFm/fr1xZuIiHHjxhVvJk2aVLypORa2devW4s2WLVuKNxERLS3D/ilNra2txZuaA2Njxowp3kTUHUlsair//U7Nz9Mpp5xSvNmzZ0/xJqLugOP27duLNzVfDzWvXc0RvYi6Q3o1j9XW1la8mTJlSvEmImLnzp3Fm9NOO63qsQ7EOwUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgCQKACRRACAN+6TmCy+8UPzJH3rooeLNVVddVbyJiNi4cWPxZu3atcWbnp6e4k17e3vxpuYKaUTdZcfRo0cXb5qbm4s3vb29xZuIiIGBgeJNzYXe7u7u4s0bb7xRvKl5bhF1r0PN1dyR+hrv6+sr3kTUXSqu2dRcVq254BoR8e53v7t4s2nTpqrHOhDvFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkBpDw7zO1Wg0DvVziYiIiy++uGp3/fXXF28mT55cvNm6dWvxpuYYV83xs4i6Q3U1B/FqDq3VPLeIuq+9mqNzNUcIazY1r3ftY43U923N4xyqg25vpeY1HxwcLN5MmTKleBMR8eKLLxZvlixZUrwZzveFdwoAJFEAIIkCAEkUAEiiAEASBQCSKACQRAGAJAoAJFEAIIkCAEkUAEjDPohXc8ys5qDUSDr33HOLN7fcckvxpubw3oQJE4o3ERFNTeWdr/m5rTmIV3vkr8bmzZuLNzVH9DZs2FC8qf2+2L17d/Gm9ghhqZrXbt++fVWP1d3dXbyp+b546qmnijerV68u3kREPPPMM1W7Ug7iAVBEFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUA0rAP4jUajUP9XPgXJ598ctVu0qRJxZsdO3YUb971rncVb9atW1e8iag7nLZmzZqqx4L/Zg7iAVBEFABIogBAEgUAkigAkEQBgCQKACRRACCJAgBJFABIogBAEgUAkigAkFxJBfgf4UoqAEVEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBEAYAkCgAkUQAgiQIASRQASKIAQBIFAJIoAJBahvuBQ0NDh/J5AHAE8E4BgCQKACRRACCJAgBJFABIogBAEgUAkigAkEQBgPR/uDyjEMKzPDMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Fashion MNIST: grayscale 28×28 images in 10 classes\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Print shapes to verify dataset dimensions\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "\n",
    "# Display the first image with its label\n",
    "plt.imshow(x_train[0], cmap='gray')           # Show pixel intensities as grayscale\n",
    "plt.title(\"Label: \" + str(y_train[0]))         # Show its numeric class label\n",
    "plt.axis('off')                                # Hide axis ticks\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbab14e",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4657b6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values from [0,255] → [0,1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test  = x_test.astype(\"float32\")  / 255.0\n",
    "\n",
    "# Add channel dimension: (28,28) → (28,28,1) required by Conv2D\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test  = np.expand_dims(x_test,  -1)\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test  = keras.utils.to_categorical(y_test,  num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891ef608",
   "metadata": {},
   "source": [
    "## Building a CNN from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c00d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │             \u001b[38;5;34m320\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m204,928\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">225,034</span> (879.04 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m225,034\u001b[0m (879.04 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def build_cnn():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),  # Convolutional layer\n",
    "        layers.MaxPooling2D((2,2)),                                          # Max pooling layer\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),                         # Another Conv layer\n",
    "        layers.MaxPooling2D((2,2)),                                          # Another pooling layer\n",
    "        layers.Flatten(),                                                    # Flatten to 1D vector\n",
    "        layers.Dense(128, activation='relu'),                                # Fully connected layer\n",
    "        layers.Dropout(0.5),                                                 # Dropout for regularization\n",
    "        layers.Dense(num_classes, activation='softmax')                      # Output layer with softmax\n",
    "    ])\n",
    "    # Compile model with optimizer, loss, and metric\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate and view model architecture\n",
    "cnn = build_cnn()\n",
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f546dd5d",
   "metadata": {},
   "source": [
    "## Training with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04a2819c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 32ms/step - accuracy: 0.6682 - loss: 0.9230 - val_accuracy: 0.8465 - val_loss: 0.4107\n",
      "Epoch 2/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.8411 - loss: 0.4350 - val_accuracy: 0.8757 - val_loss: 0.3348\n",
      "Epoch 3/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.8653 - loss: 0.3777 - val_accuracy: 0.8808 - val_loss: 0.3150\n",
      "Epoch 4/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.8789 - loss: 0.3390 - val_accuracy: 0.8880 - val_loss: 0.2958\n",
      "Epoch 5/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.8867 - loss: 0.3140 - val_accuracy: 0.8917 - val_loss: 0.2889\n",
      "Epoch 6/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.8906 - loss: 0.2993 - val_accuracy: 0.8985 - val_loss: 0.2747\n",
      "Epoch 7/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.8959 - loss: 0.2828 - val_accuracy: 0.8993 - val_loss: 0.2712\n",
      "Epoch 8/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9030 - loss: 0.2642 - val_accuracy: 0.8965 - val_loss: 0.2637\n",
      "Epoch 9/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9062 - loss: 0.2566 - val_accuracy: 0.9042 - val_loss: 0.2522\n",
      "Epoch 10/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9134 - loss: 0.2370 - val_accuracy: 0.9090 - val_loss: 0.2473\n",
      "Epoch 11/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9154 - loss: 0.2310 - val_accuracy: 0.9115 - val_loss: 0.2418\n",
      "Epoch 12/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9195 - loss: 0.2203 - val_accuracy: 0.9098 - val_loss: 0.2399\n",
      "Epoch 13/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9214 - loss: 0.2125 - val_accuracy: 0.9138 - val_loss: 0.2350\n",
      "Epoch 14/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.9228 - loss: 0.2047 - val_accuracy: 0.9177 - val_loss: 0.2327\n",
      "Epoch 15/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9273 - loss: 0.1938 - val_accuracy: 0.9148 - val_loss: 0.2371\n",
      "Epoch 16/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 34ms/step - accuracy: 0.9292 - loss: 0.1859 - val_accuracy: 0.9193 - val_loss: 0.2294\n",
      "Epoch 17/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9322 - loss: 0.1786 - val_accuracy: 0.9157 - val_loss: 0.2372\n",
      "Epoch 18/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 29ms/step - accuracy: 0.9351 - loss: 0.1721 - val_accuracy: 0.9225 - val_loss: 0.2320\n",
      "Epoch 19/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 31ms/step - accuracy: 0.9382 - loss: 0.1663 - val_accuracy: 0.9218 - val_loss: 0.2250\n",
      "Epoch 20/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 30ms/step - accuracy: 0.9402 - loss: 0.1585 - val_accuracy: 0.9195 - val_loss: 0.2379\n"
     ]
    }
   ],
   "source": [
    "# EarlyStopping: stop training when validation loss stops improving for 3 epochs\n",
    "early_stop = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# TensorBoard: log training metrics and histograms for inspection\n",
    "tensorboard_cb = callbacks.TensorBoard(\n",
    "    log_dir=\"logs\",\n",
    "    histogram_freq=1\n",
    ")\n",
    "\n",
    "# ModelCheckpoint: save the best model (in Keras’s native format) by validation accuracy\n",
    "# Note: Keras now requires the .keras extension for full model saving\n",
    "mc = callbacks.ModelCheckpoint(\n",
    "    filepath='best_model.keras',    # Must end in .keras when save_weights_only=False\n",
    "    monitor='val_accuracy',         # Which metric to monitor\n",
    "    save_best_only=True             # Only save when the monitored metric improves\n",
    ")\n",
    "\n",
    "# Train the model with a 10% validation split and the above callbacks\n",
    "history = cnn.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=128,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop, tensorboard_cb, mc]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fa08bd",
   "metadata": {},
   "source": [
    "## Visualizing Training with TensorBoard\n",
    "```bash\n",
    "tensorboard --logdir logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f04d96",
   "metadata": {},
   "source": [
    "## Evaluation & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76d7c024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.0950, Test Loss: 2.3203\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "test_loss, test_acc = cnn.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_acc:.4f}, Test Loss: {test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d58e7b",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "125055d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 59ms/step - accuracy: 0.5498 - loss: 1.2255 - val_accuracy: 0.7745 - val_loss: 0.5772\n",
      "Epoch 2/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 61ms/step - accuracy: 0.7418 - loss: 0.6943 - val_accuracy: 0.8001 - val_loss: 0.5295\n",
      "Epoch 3/20\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - accuracy: 0.7594 - loss: 0.6299 - val_accuracy: 0.8259 - val_loss: 0.4570\n"
     ]
    }
   ],
   "source": [
    "# Configure image augmentations\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "    rotation_range=15, width_shift_range=0.1, height_shift_range=0.1,\n",
    "    zoom_range=0.1, horizontal_flip=True\n",
    ")\n",
    "datagen.fit(x_train)\n",
    "\n",
    "# Train with augmented data\n",
    "aug_cnn = build_cnn()\n",
    "aug_history = aug_cnn.fit(\n",
    "    datagen.flow(x_train, y_train, batch_size=128),\n",
    "    epochs=20,\n",
    "    validation_data=(x_test, y_test),\n",
    "    callbacks=[early_stop, mc]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a31e00",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Keras Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf18b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from .\\untitled_project\\tuner0.json\n",
      "WARNING:tensorflow:From C:\\Users\\ISHA\\anaconda3\\lib\\site-packages\\keras\\src\\backend\\common\\global_state.py:82: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ISHA\\anaconda3\\lib\\site-packages\\keras\\src\\saving\\saving_lib.py:418: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  trackable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    }
   ],
   "source": [
    "def model_builder(hp):\n",
    "    # Number of units in dense layer\n",
    "    hp_units = hp.Int('units', min_value=32, max_value=256, step=32)\n",
    "    # Learning rate options\n",
    "    hp_lr = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "    model = build_cnn()\n",
    "    # Modify dense layer units\n",
    "    model.layers[-2] = layers.Dense(hp_units, activation='relu')\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=hp_lr),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Run random search\n",
    "tuner = kt.RandomSearch(model_builder, objective='val_accuracy', max_trials=5, executions_per_trial=1)\n",
    "tuner.search(x_train, y_train, epochs=5, validation_split=0.1)\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b9adf",
   "metadata": {},
   "source": [
    "## Transfer Learning (Advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b65d90ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ up_sampling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)         │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_96 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ ?                           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ up_sampling2d (\u001b[38;5;33mUpSampling2D\u001b[0m)         │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ mobilenetv2_1.00_96 (\u001b[38;5;33mFunctional\u001b[0m)     │ ?                           │       \u001b[38;5;34m2,257,984\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_average_pooling2d             │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)             │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,257,984</span> (8.61 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,257,984\u001b[0m (8.61 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load pretrained MobileNetV2 (no top)\n",
    "base = keras.applications.MobileNetV2(weights='imagenet', include_top=False, input_shape=(96,96,3))\n",
    "base.trainable = False  # Freeze base\n",
    "\n",
    "# Build new model on top\n",
    "tl_model = models.Sequential([\n",
    "    layers.UpSampling2D((12,12)),    # Upsample input\n",
    "    base,                             # Pretrained base\n",
    "    layers.GlobalAveragePooling2D(),  # Pool features\n",
    "    layers.Dense(64, activation='relu'),  \n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "tl_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "tl_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf09705",
   "metadata": {},
   "source": [
    "##  Custom Training Loop with tf.GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51e828c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4342\n",
      "Epoch 2, Loss: 0.3407\n",
      "Epoch 3, Loss: 0.3133\n",
      "Epoch 4, Loss: 0.3123\n",
      "Epoch 5, Loss: 0.2056\n"
     ]
    }
   ],
   "source": [
    "# Define optimizer and loss\n",
    "optimizer = keras.optimizers.Adam()\n",
    "loss_fn = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# Create batched dataset\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)\n",
    "\n",
    "for epoch in range(5):\n",
    "    for images, labels in train_ds:\n",
    "        # Record operations\n",
    "        with tf.GradientTape() as tape:\n",
    "            preds = cnn(images, training=True)\n",
    "            loss = loss_fn(labels, preds)\n",
    "        # Compute gradients\n",
    "        grads = tape.gradient(loss, cnn.trainable_variables)\n",
    "        # Apply gradients\n",
    "        optimizer.apply_gradients(zip(grads, cnn.trainable_variables))\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cc6e2",
   "metadata": {},
   "source": [
    "##  Mixed Precision & Multi-GPU Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1fc2315d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Epoch 1/3\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 2s/step - accuracy: 0.6135 - loss: 1.0769\n",
      "Epoch 2/3\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m380s\u001b[0m 2s/step - accuracy: 0.8250 - loss: 0.4886\n",
      "Epoch 3/3\n",
      "\u001b[1m235/235\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 2s/step - accuracy: 0.8517 - loss: 0.4115\n"
     ]
    }
   ],
   "source": [
    "# Enable mixed precision\n",
    "tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "\n",
    "# Use all GPUs\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    dist_model = build_cnn()\n",
    "    dist_model.fit(x_train, y_train, epochs=3, batch_size=256)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
